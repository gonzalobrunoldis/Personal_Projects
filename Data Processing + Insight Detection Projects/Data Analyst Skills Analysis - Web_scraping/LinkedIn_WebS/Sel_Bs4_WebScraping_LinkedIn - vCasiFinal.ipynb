{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3223f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOs \n",
    "# Add the case when we DO have yesterday's scrapped companies but we don't have today's scrapped companies cause the day just changed\n",
    "# Add Data Origin (Linkedin in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b01e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import date, timedelta, datetime\n",
    "from IPython.core.display import clear_output\n",
    "from random import randint\n",
    "from requests import get\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "from urllib.request import urlopen as ureq\n",
    "import urllib\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48b189",
   "metadata": {},
   "source": [
    "# Scraping for job in AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d1a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://au.linkedin.com/jobs/data-analyst-jobs-sydney-nsw?keywords=Data%20Analyst&location=Sydney%2C%20New%20South%20Wales%2C%20Australia&locationId=&geoId=104769905&sortBy=DD&f_TPR=r86400&distance=25&position=1&pageNum=0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bbd03",
   "metadata": {},
   "source": [
    "### Opening up connection and getting HTML info from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02be8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4db623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New jobs posted within set timeframe\n",
    "new_jobs_posted = int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text) - (int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text)*0.2)\n",
    "new_jobs_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e26e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contenedores = []\n",
    "\n",
    "while len(contenedores) < new_jobs_posted:\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//button[@class=\"infinite-scroller__show-more-button infinite-scroller__show-more-button--visible\"]').click()\n",
    "    except:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        contenedores = driver.find_elements_by_xpath('//div[@class=\"base-card base-card--link base-search-card base-search-card--link job-search-card\"]')\n",
    "        sleep(random.uniform(4.0,8.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa95e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contenedores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58a78cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"f1722af644aa34f0170063325c4e409a\", element=\"750bd620-152d-49a1-962c-6dec8f975791\")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenedores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad72591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business Analyst\\nWestpac Group\\nSydney, New South Wales, Australia\\nBe an early applicant\\n1 hour ago'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenedores[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf74e8",
   "metadata": {},
   "source": [
    "### Retrieving all the DIVs that contain job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7033c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job titles\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "date_scraped=[]\n",
    "links=[]\n",
    "job_industry=[]\n",
    "job_desc=[]\n",
    "job_type=[]\n",
    "job_seniority=[]\n",
    "\n",
    "counter=1\n",
    "\n",
    "#Check for the app to stop if the job was already scrapped\n",
    "df = pd.read_csv('Linkedin_data_info_au.csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62ec687",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    last_index_in_csv = int(df.iloc[-1]['Unnamed: 0'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34082554",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Date Scraped']).replace(to_replace=r'\\/',value='-',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25fc65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get jobs posted today and yesterday. If yesteday cannot be found, get the jobs added today. If neither can be found, instantiate empty variables\n",
    "try:\n",
    "    job_title_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0],df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]]\n",
    "    company_name_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0], df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]]\n",
    "except: \n",
    "    try:\n",
    "        job_title_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0]\n",
    "        company_name_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0]\n",
    "    except:\n",
    "        try:\n",
    "            job_title_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]\n",
    "            company_name_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]\n",
    "        except:\n",
    "            job_title_check=''\n",
    "            company_name_check=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9538c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ec771a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06a19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the data\n",
    "for job_post in contenedores:\n",
    "    job_title=job_post.find_element_by_xpath('.//h3[@class=\"base-search-card__title\"]').text\n",
    "    job_company_name=job_post.find_element_by_xpath('.//h4[@class=\"base-search-card__subtitle\"]').text\n",
    "    if job_title==job_title_check and job_company_name==company_name_check:\n",
    "        break\n",
    "    #Job title\n",
    "    job_titles.append(job_title)\n",
    "    #Company name\n",
    "    company_name.append(job_company_name)\n",
    "    #Job Location\n",
    "    job_location.append(job_post.find_element_by_xpath('.//span[@class=\"job-search-card__location\"]').text)\n",
    "    #Date scraped\n",
    "    date_scraped.append(str(date.today()))\n",
    "    #Job link\n",
    "    links.append(job_post.find_element_by_xpath('.//a[@class=\"base-card__full-link\"]').get_attribute('href'))\n",
    "    #Retrieve Job Type, Industry and Seniority\n",
    "    driver.find_elements_by_xpath('//a[@class=\"base-card__full-link\"]')[counter].click()\n",
    "    sleep(random.uniform(2.1,5.6))\n",
    "    job_desc.append(driver.find_element_by_xpath('.//section[@class=\"description\"]/div/section/div').text.strip())\n",
    "    \n",
    "    try:\n",
    "        job_type.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[2]').text.strip())\n",
    "        job_industry.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[4]').text)\n",
    "        job_seniority.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[1]').text.strip())\n",
    "    except:\n",
    "        job_industry.append('NA')\n",
    "        job_type.append('NA')\n",
    "        job_seniority.append('NA')\n",
    "\n",
    "    counter=counter+1\n",
    "    sleep(random.uniform(1.0,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dedd6211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business Analyst'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenedores[0].find_element_by_xpath('.//h3[@class=\"base-search-card__title\"]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62bc2e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job titles ----\n",
      "98\n",
      "['Business Analyst', 'Senior Associate, Customer Remediation Analytics']\n",
      "Job company ----\n",
      "98\n",
      "['Westpac Group', 'Westpac Institutional Bank']\n",
      "Job Location ----\n",
      "98\n",
      "['Sydney, New South Wales, Australia', 'Sydney, New South Wales, Australia']\n",
      "Date scraped ----\n",
      "98\n",
      "['2021-08-27', '2021-08-27']\n",
      "Job links ----\n",
      "98\n",
      "['https://au.linkedin.com/jobs/view/business-analyst-at-westpac-group-2669985490?refId=KrVGxPRtRwDQXXR1DqUK%2FA%3D%3D&trackingId=2%2FXFwKS84gaW4Dnv1l5Fvg%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://au.linkedin.com/jobs/view/senior-associate-customer-remediation-analytics-at-westpac-institutional-bank-2693196354?refId=KrVGxPRtRwDQXXR1DqUK%2FA%3D%3D&trackingId=1cc0n5ycVBSiPgFnBYGlgw%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card']\n",
      "Job type ----\n",
      "98\n",
      "['Employment type\\nFull-time', 'Employment type\\nFull-time']\n",
      "Job industry ----\n",
      "['Industries\\nBanking, Financial Services, and Investment Banking', 'Industries\\nBanking, Financial Services, and Investment Banking']\n",
      "Job seniority ----\n",
      "['Seniority level\\nNot Applicable', 'Seniority level\\nNot Applicable']\n"
     ]
    }
   ],
   "source": [
    "print('Job titles ----')\n",
    "print(len(job_titles))    \n",
    "print(job_titles[0:2])\n",
    "print('Job company ----')\n",
    "print(len(company_name))\n",
    "print(company_name[0:2])\n",
    "print('Job Location ----')\n",
    "print(len(job_location))\n",
    "print(job_location[0:2])\n",
    "print('Date scraped ----')\n",
    "print(len(date_scraped))\n",
    "print(date_scraped[0:2])\n",
    "print('Job links ----')\n",
    "print(len(links))\n",
    "print(links[0:2])\n",
    "print('Job type ----')\n",
    "print(len(job_type))\n",
    "print(job_type[0:2])\n",
    "print('Job industry ----')\n",
    "print(job_industry[0:2])\n",
    "print('Job seniority ----')\n",
    "print(job_seniority[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad38ee",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09cdfc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_structure = {'Job Title': job_titles, 'Company Name':company_name, 'Location':job_location, 'Date Scraped':date_scraped, 'Job URL':links, 'Job Industry':job_industry, 'Job Type':job_type, 'Job Seniority':job_seniority, 'Job Description':job_desc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4fba04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    last_index_in_csv_1 = last_index_in_csv+1\n",
    "except:\n",
    "    last_index_in_csv_1= 0\n",
    "df = pd.DataFrame(dataframe_structure)\n",
    "df.index += last_index_in_csv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf758ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Industry'] = df['Job Industry'].replace(r'Industries\\n','',regex=True)\n",
    "df['Job Seniority'] = df['Job Seniority'].replace(r'Seniority level\\n','',regex=True)\n",
    "df['Job Description'] = df['Job Description'].replace(r'Job Description\\n','',regex=True).replace(r'\\n',' ',regex=True)\n",
    "df['Job Type'] = df['Job Type'].replace(r'Employment Type\\n','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e595d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Linkedin_data_info_au.csv',mode='a',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0cc6b",
   "metadata": {},
   "source": [
    "# Scraping for job in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1060ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://au.linkedin.com/jobs/search?keywords=Data%20Analyst&location=United%20States&locationId=&geoId=103644278&sortBy=DD&f_TPR=r86400&position=1&pageNum=0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfa5a9",
   "metadata": {},
   "source": [
    "### Opening up connection and getting HTML info from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "663b2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f675e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    new_jobs_posted = re.findall('\\d+',driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text)\n",
    "    new_jobs_posted = int(\"\".join(new_jobs_posted))\n",
    "except:\n",
    "    new_jobs_posted = int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text) - (int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text)*0.2)\n",
    "\n",
    "if new_jobs_posted > 400:\n",
    "    new_jobs_posted = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ea4d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "contenedores = []\n",
    "\n",
    "while len(contenedores) < new_jobs_posted:\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        driver.find_element_by_xpath('//button[@class=\"infinite-scroller__show-more-button infinite-scroller__show-more-button--visible\"]').click()\n",
    "        contenedores = driver.find_elements_by_xpath('//div[@class=\"base-card base-card--link base-search-card base-search-card--link job-search-card\"]')\n",
    "        sleep(random.uniform(1.7,5.3))\n",
    "    except:\n",
    "        driver.execute_script(\"window.scrollTo(0, 200)\")\n",
    "        sleep(random.uniform(0.7,1.3))\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        contenedores = driver.find_elements_by_xpath('//div[@class=\"base-card base-card--link base-search-card base-search-card--link job-search-card\"]')\n",
    "        sleep(random.uniform(4.0,8.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66101e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contenedores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd2f56e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_jobs_posted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e82526",
   "metadata": {},
   "source": [
    "### Retrieving all the DIVs that contain job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "508baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job titles\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "date_scraped=[]\n",
    "links=[]\n",
    "job_industry=[]\n",
    "job_desc=[]\n",
    "job_type=[]\n",
    "job_seniority=[]\n",
    "\n",
    "counter=1\n",
    "\n",
    "#Check for the app to stop if the job was already scrapped\n",
    "try:\n",
    "    df = pd.read_csv('Linkedin_data_info_us.csv', engine='python')\n",
    "    last_index_in_csv = int(df.iloc[-1]['Unnamed: 0']) \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "142efeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    (df['Date Scraped']).replace(to_replace=r'\\/',value='-',regex=True,inplace=True)\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8089247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get jobs posted today and yesterday. If yesteday cannot be found, get the jobs added today. If neither can be found, instantiate empty variables\n",
    "try:\n",
    "    job_title_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0],df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]]\n",
    "    company_name_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0], df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]]\n",
    "except: \n",
    "    try:\n",
    "        job_title_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0]\n",
    "        company_name_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0]\n",
    "    except:\n",
    "        try:\n",
    "            job_title_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]\n",
    "            company_name_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]\n",
    "        except:\n",
    "            job_title_check=''\n",
    "            company_name_check=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c72059ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0cc1f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdd7f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the data\n",
    "for job_post in contenedores:\n",
    "    job_title=job_post.find_element_by_xpath('.//h3[@class=\"base-search-card__title\"]').text\n",
    "    job_company_name=job_post.find_element_by_xpath('.//h4[@class=\"base-search-card__subtitle\"]').text\n",
    "    if job_title==job_title_check and job_company_name==company_name_check:\n",
    "        break\n",
    "    #Job title\n",
    "    job_titles.append(job_title)\n",
    "    #Company name\n",
    "    company_name.append(job_company_name)\n",
    "    #Job Location\n",
    "    job_location.append(job_post.find_element_by_xpath('.//span[@class=\"job-search-card__location\"]').text)\n",
    "    #Date scraped\n",
    "    date_scraped.append(str(date.today()))\n",
    "    #Job link\n",
    "    links.append(job_post.find_element_by_xpath('.//a[@class=\"base-card__full-link\"]').get_attribute('href'))\n",
    "    #Retrieve Job Type, Industry and Seniority\n",
    "    driver.find_elements_by_xpath('//a[@class=\"base-card__full-link\"]')[counter].click()\n",
    "    sleep(random.uniform(2.1,5.6))\n",
    "    job_desc.append(driver.find_element_by_xpath('.//section[@class=\"description\"]/div/section/div').text.strip())\n",
    "    \n",
    "    try:\n",
    "        job_type.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[2]').text.strip())\n",
    "        job_industry.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[4]').text)\n",
    "        job_seniority.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[1]').text.strip())\n",
    "    except:\n",
    "        job_industry.append('NA')\n",
    "        job_type.append('NA')\n",
    "        job_seniority.append('NA')\n",
    "\n",
    "    counter=counter+1\n",
    "    sleep(random.uniform(1.0,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "986357b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job titles ----\n",
      "424\n",
      "['Software Engineer, Mobile Developer Productivity', 'Data Scientist, Credit Risk']\n",
      "Job company ----\n",
      "424\n",
      "['Stripe', 'Stripe']\n",
      "Job Location ----\n",
      "424\n",
      "['United States', 'Seattle, WA']\n",
      "Date scraped ----\n",
      "424\n",
      "['2021-08-27', '2021-08-27']\n",
      "Job links ----\n",
      "424\n",
      "['https://www.linkedin.com/jobs/view/software-engineer-mobile-developer-productivity-at-stripe-2431522021?refId=rg%2FwqksdU1%2FGCrlPCaX2Cg%3D%3D&trackingId=AQZJSEiaDcdXwzcwAXDm2w%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://www.linkedin.com/jobs/view/data-scientist-credit-risk-at-stripe-2607184408?refId=rg%2FwqksdU1%2FGCrlPCaX2Cg%3D%3D&trackingId=%2BjiMAo5o3g4MDN0wTLlZxw%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card']\n",
      "Job type ----\n",
      "424\n",
      "['Employment type\\nFull-time', 'Employment type\\nFull-time']\n",
      "Job industry ----\n",
      "['Industries\\nComputer Software, Financial Services, and Internet', 'Industries\\nComputer Software, Financial Services, and Internet']\n",
      "Job seniority ----\n",
      "['Seniority level\\nMid-Senior level', 'Seniority level\\nMid-Senior level']\n"
     ]
    }
   ],
   "source": [
    "print('Job titles ----')\n",
    "print(len(job_titles))    \n",
    "print(job_titles[0:2])\n",
    "print('Job company ----')\n",
    "print(len(company_name))\n",
    "print(company_name[0:2])\n",
    "print('Job Location ----')\n",
    "print(len(job_location))\n",
    "print(job_location[0:2])\n",
    "print('Date scraped ----')\n",
    "print(len(date_scraped))\n",
    "print(date_scraped[0:2])\n",
    "print('Job links ----')\n",
    "print(len(links))\n",
    "print(links[0:2])\n",
    "print('Job type ----')\n",
    "print(len(job_type))\n",
    "print(job_type[0:2])\n",
    "print('Job industry ----')\n",
    "print(job_industry[0:2])\n",
    "print('Job seniority ----')\n",
    "print(job_seniority[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb96c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_structure = {'Job Title': job_titles, 'Company Name':company_name, 'Location':job_location, 'Date Scraped':date_scraped, 'Job URL':links, 'Job Industry':job_industry, 'Job Type':job_type, 'Job Seniority':job_seniority, 'Job Description':job_desc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f667ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    last_index_in_csv_1 = last_index_in_csv+1\n",
    "except:\n",
    "    last_index_in_csv_1 = 0\n",
    "df = pd.DataFrame(dataframe_structure)\n",
    "df.index += last_index_in_csv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b207e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Industry'] = df['Job Industry'].replace(r'Industries\\n','',regex=True)\n",
    "df['Job Seniority'] = df['Job Seniority'].replace(r'Seniority level\\n','',regex=True)\n",
    "df['Job Description'] = df['Job Description'].replace(r'Job Description\\n','',regex=True).replace(r'\\n',' ',regex=True)\n",
    "df['Job Type'] = df['Job Type'].replace(r'Employment Type\\n','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f191edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Linkedin_data_info_us.csv',mode='a',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46542b9d",
   "metadata": {},
   "source": [
    "# Scraping for job in Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8837958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://au.linkedin.com/jobs/search?keywords=Data%20Analyst&location=Spain&locationId=&geoId=105646813&sortBy=DD&f_TPR=r86400&position=1&pageNum=0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cfc8d1",
   "metadata": {},
   "source": [
    "### Opening up connection and getting HTML info from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7890a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d697ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New jobs posted within set timeframe\n",
    "new_jobs_posted = int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text) - (int(driver.find_element_by_xpath('//span[@class=\"results-context-header__job-count\"]').text)*0.2)\n",
    "new_jobs_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9060f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "contenedores = []\n",
    "\n",
    "while len(contenedores) < new_jobs_posted:\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        driver.find_element_by_xpath('//button[@class=\"infinite-scroller__show-more-button infinite-scroller__show-more-button--visible\"]').click()\n",
    "        contenedores = driver.find_elements_by_xpath('//div[@class=\"base-card base-card--link base-search-card base-search-card--link job-search-card\"]')\n",
    "        sleep(random.uniform(1.7,5.3))\n",
    "    except:\n",
    "        driver.execute_script(\"window.scrollTo(0, 200)\")\n",
    "        sleep(random.uniform(0.7,1.3))\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        contenedores = driver.find_elements_by_xpath('//div[@class=\"base-card base-card--link base-search-card base-search-card--link job-search-card\"]')\n",
    "        sleep(random.uniform(4.0,8.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb3ec8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contenedores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89c18eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"7292becbcb4618e57ade671df81a37a3\", element=\"e5eb0aa9-c5fd-47e8-9b7f-e256325a5b85\")>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenedores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35581be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quality & Statistics Analyst\\nKantar\\nSant Cugat del Vallès, Catalonia, Spain\\nBe an early applicant\\n2 minutes ago'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenedores[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52f0d2c",
   "metadata": {},
   "source": [
    "### Retrieving all the DIVs that contain job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05d6a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Job titles\n",
    "job_titles=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "date_scraped=[]\n",
    "links=[]\n",
    "job_industry=[]\n",
    "job_desc=[]\n",
    "job_type=[]\n",
    "job_seniority=[]\n",
    "\n",
    "counter=1\n",
    "\n",
    "#Check for the app to stop if the job was already scrapped\n",
    "try:\n",
    "    df = pd.read_csv('Linkedin_data_info_sp.csv', engine='python')\n",
    "    last_index_in_csv = int(df.iloc[-1]['Unnamed: 0'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44a65ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    (df['Date Scraped']).replace(to_replace=r'\\/',value='-',regex=True,inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fdccc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get jobs posted today and yesterday. If yesteday cannot be found, get the jobs added today. If neither can be found, instantiate empty variables\n",
    "try:\n",
    "    job_title_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0],df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]]\n",
    "    company_name_check = [df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0], df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]]\n",
    "except: \n",
    "    try:\n",
    "        job_title_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Job Title'].iloc[0]\n",
    "        company_name_check = df[df['Date Scraped']==str(date.today().strftime('%d-%m-%Y'))]['Company Name'].iloc[0]\n",
    "    except:\n",
    "        try:\n",
    "            job_title_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Job Title'].iloc[0]\n",
    "            company_name_check = df[df['Date Scraped']==(date.today() - timedelta(days=1)).strftime('%d-%m-%Y')]['Company Name'].iloc[0]\n",
    "        except:\n",
    "            job_title_check=''\n",
    "            company_name_check=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bdb03b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20988503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba7dcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the data\n",
    "for job_post in contenedores:\n",
    "    job_title=job_post.find_element_by_xpath('.//h3[@class=\"base-search-card__title\"]').text\n",
    "    job_company_name=job_post.find_element_by_xpath('.//h4[@class=\"base-search-card__subtitle\"]').text\n",
    "    if job_title==job_title_check and job_company_name==company_name_check:\n",
    "        break\n",
    "    #Job title\n",
    "    job_titles.append(job_title)\n",
    "    #Company name\n",
    "    company_name.append(job_company_name)\n",
    "    #Job Location\n",
    "    job_location.append(job_post.find_element_by_xpath('.//span[@class=\"job-search-card__location\"]').text)\n",
    "    #Date scraped\n",
    "    date_scraped.append(str(date.today()))\n",
    "    #Job link\n",
    "    links.append(job_post.find_element_by_xpath('.//a[@class=\"base-card__full-link\"]').get_attribute('href'))\n",
    "    #Retrieve Job Type, Industry and Seniority\n",
    "    driver.find_elements_by_xpath('//a[@class=\"base-card__full-link\"]')[counter].click()\n",
    "    sleep(random.uniform(2.1,5.6))\n",
    "    job_desc.append(driver.find_element_by_xpath('.//section[@class=\"description\"]/div/section/div').text.strip())\n",
    "    \n",
    "    try:\n",
    "        job_type.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[2]').text.strip())\n",
    "        job_industry.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[4]').text)\n",
    "        job_seniority.append(driver.find_element_by_xpath('.//ul[@class=\"description__job-criteria-list\"]/li[1]').text.strip())\n",
    "    except:\n",
    "        job_industry.append('NA')\n",
    "        job_type.append('NA')\n",
    "        job_seniority.append('NA')\n",
    "\n",
    "    counter=counter+1\n",
    "    sleep(random.uniform(1.0,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1055cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job titles ----\n",
      "95\n",
      "['Quality & Statistics Analyst', 'Data Engineer_Scala. Inglés Alto']\n",
      "Job company ----\n",
      "95\n",
      "['Kantar', 'CGI']\n",
      "Job Location ----\n",
      "95\n",
      "['Sant Cugat del Vallès, Catalonia, Spain', 'Greater Madrid Metropolitan Area']\n",
      "Date scraped ----\n",
      "95\n",
      "['2021-08-27', '2021-08-27']\n",
      "Job links ----\n",
      "95\n",
      "['https://es.linkedin.com/jobs/view/quality-statistics-analyst-at-kantar-2694588069?refId=76RAULkUHnJbxypxLgrrkA%3D%3D&trackingId=gA6BK3vP%2FV9GKQu706Mxyw%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card', 'https://es.linkedin.com/jobs/view/data-engineer-scala-ingl%C3%A9s-alto-at-cgi-2694583852?refId=76RAULkUHnJbxypxLgrrkA%3D%3D&trackingId=%2FtXJ%2B5rtl7lgVXrC2qG%2B8A%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card']\n",
      "Job type ----\n",
      "95\n",
      "['Employment type\\nFull-time', 'Employment type\\nFull-time']\n",
      "Job industry ----\n",
      "['Industries\\nMarket Research', 'Industries\\nInformation Technology and Services']\n",
      "Job seniority ----\n",
      "['Seniority level\\nAssociate', 'Seniority level\\nAssociate']\n"
     ]
    }
   ],
   "source": [
    "print('Job titles ----')\n",
    "print(len(job_titles))    \n",
    "print(job_titles[0:2])\n",
    "print('Job company ----')\n",
    "print(len(company_name))\n",
    "print(company_name[0:2])\n",
    "print('Job Location ----')\n",
    "print(len(job_location))\n",
    "print(job_location[0:2])\n",
    "print('Date scraped ----')\n",
    "print(len(date_scraped))\n",
    "print(date_scraped[0:2])\n",
    "print('Job links ----')\n",
    "print(len(links))\n",
    "print(links[0:2])\n",
    "print('Job type ----')\n",
    "print(len(job_type))\n",
    "print(job_type[0:2])\n",
    "print('Job industry ----')\n",
    "print(job_industry[0:2])\n",
    "print('Job seniority ----')\n",
    "print(job_seniority[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101e34c",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f59f46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_structure = {'Job Title': job_titles, 'Company Name':company_name, 'Location':job_location, 'Date Scraped':date_scraped, 'Job URL':links, 'Job Industry':job_industry, 'Job Type':job_type, 'Job Seniority':job_seniority, 'Job Description':job_desc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d55d3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    last_index_in_csv_1 = last_index_in_csv+1\n",
    "except:\n",
    "    last_index_in_csv_1 = 0\n",
    "df = pd.DataFrame(dataframe_structure)\n",
    "df.index += last_index_in_csv_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df13d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Industry'] = df['Job Industry'].replace(r'Industries\\n','',regex=True)\n",
    "df['Job Seniority'] = df['Job Seniority'].replace(r'Seniority level\\n','',regex=True)\n",
    "df['Job Description'] = df['Job Description'].replace(r'Job Description\\n','',regex=True).replace(r'\\n',' ',regex=True)\n",
    "df['Job Type'] = df['Job Type'].replace(r'Employment Type\\n','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01e9b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Linkedin_data_info_sp.csv',mode='a',header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
